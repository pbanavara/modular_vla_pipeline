{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3d43ed9-8dde-4ea5-9c7f-6a5cd57014c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "import json\n",
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f6283565-53c4-4703-a428-c5a09772064b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['burnt', 'casserole', 'coffee', 'cups', 'dirty', 'dutch', 'food', 'oven', 'pan', 'residue', 'stains', 'wok']\n"
     ]
    }
   ],
   "source": [
    "with open(\"src/labeled_data.json\", \"r\") as f:\n",
    "    labeled_data = json.load(f)\n",
    "\n",
    "# Extract unique labels and create a mapping\n",
    "all_labels = sorted({label for item in labeled_data for label in item[\"labels\"]})\n",
    "label_to_idx = {label: i for i, label in enumerate(all_labels)}\n",
    "print(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8d490db-55d3-4c9a-a72f-d9003a816264",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DishDataset(Dataset):\n",
    "    def __init__(self, labeled_data, image_dir, transform=None):\n",
    "        self.labeled_data = labeled_data\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labeled_data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = self.labeled_data[idx]\n",
    "        img_path = os.path.join(self.image_dir, item[\"filename\"])\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        \n",
    "        # Create multi-hot encoded label vector\n",
    "        label_vector = torch.zeros(len(all_labels))\n",
    "        for label in item[\"labels\"]:\n",
    "            label_vector[label_to_idx[label]] = 1.0\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5b9764e-65bc-4469-ab05-fdc600c34f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define image transforms (resize, normalize, augment)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize for EfficientNet\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b31ad566-8de6-4b6a-aaff-815850c8ed0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = \"src/dataset/dirty_dishes\"\n",
    "dataset = DishDataset(labeled_data, image_dir, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4551e076-8c72-4ad4-9fbd-b332c56492e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d53290a8-c3e8-4542-9eb7-0916a278ea66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pbanavara/miniforge3/envs/pytorch/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/pbanavara/miniforge3/envs/pytorch/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-7f5810bc.pth\" to /Users/pbanavara/.cache/torch/hub/checkpoints/efficientnet_b0_rwightman-7f5810bc.pth\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20.5M/20.5M [00:00<00:00, 33.3MB/s]\n"
     ]
    }
   ],
   "source": [
    "model = models.efficientnet_b0(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "504d5617-89f2-4406-855a-aa9429bee210",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(all_labels)\n",
    "model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e13d225d-67a4-481a-b75b-b827e5be2539",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\")\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "081f15db-3083-4a14-b68e-135a02750d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function (multi-label classification)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c944496f-8398-4b85-8cda-a63306ce5e53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.3365\n",
      "Epoch 2/10, Loss: 0.1568\n",
      "Epoch 3/10, Loss: 0.1089\n",
      "Epoch 4/10, Loss: 0.0928\n",
      "Epoch 5/10, Loss: 0.0801\n",
      "Epoch 6/10, Loss: 0.0755\n",
      "Epoch 7/10, Loss: 0.0703\n",
      "Epoch 8/10, Loss: 0.0668\n",
      "Epoch 9/10, Loss: 0.0617\n",
      "Epoch 10/10, Loss: 0.0613\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)  # Logits\n",
    "        loss = criterion(outputs, labels)  # BCEWithLogitsLoss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss/len(train_loader):.4f}\")\n",
    "\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "51ad2709-ad86-4ea6-8660-6cfaceaaeff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"efficientnet_multilabel.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "249c6c1e-480f-4d3e-9a7a-64c174afb218",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(image_path, model, transform, threshold=0.5):\n",
    "    model.eval()\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    image = transform(image).unsqueeze(0).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        logits = model(image)\n",
    "        probs = torch.sigmoid(logits).squeeze(0)  # Convert logits to probabilities\n",
    "    \n",
    "    predicted_labels = [all_labels[i] for i, prob in enumerate(probs) if prob > threshold]\n",
    "    \n",
    "    return predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3472180b-6904-4408-8036-5545ab17cef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Labels: ['stains']\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"efficientnet_multilabel.pth\"))\n",
    "model.to(device)\n",
    "\n",
    "# Example prediction\n",
    "image_path = \"test_sink_image.png\"\n",
    "predicted_labels = predict(image_path, model, transform)\n",
    "print(\"Predicted Labels:\", predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b917ba2-9c40-4369-b283-bbde22a01e5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
